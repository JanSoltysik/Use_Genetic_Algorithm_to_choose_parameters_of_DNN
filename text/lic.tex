\documentclass{article}

\usepackage{polski}
\usepackage[utf8]{inputenc}
\usepackage[ruled,vlined]{algorithm2e}
\usepackage{indentfirst}
\usepackage{amssymb}
\usepackage[colorlinks=true]{hyperref}
\usepackage[margin=1.3in]{geometry}

\usepackage{graphicx}
\usepackage{float}
\graphicspath{ {./images/} }

\usepackage[backend=biber]{biblatex}
\addbibresource{bibliography.bib}

\usepackage{amsmath}
\renewcommand{\vec}[1]{\mathbf{#1}}

\title{GA \& DNN}
\author{Jan Sołtysik}


\begin{document}
\maketitle
\tableofcontents


\section{Wstęp}


\section{Wprowadzenie teoretyczne}

\subsection{Algorytm Genetyczny}
Algorytmy genetyczne są to algorytmy poszukiwania zainspirowane mechanizmem doboru naturalnego
oraz dziedziczności. Łączą w sobie  zasadę przeżycia najlepiej przystosowanych 
osobników z systematyczną, choć zrandomizowaną wymianą informacji wprowadzoną przez
operatory genetyczne takie jak krzyżowanie i mutacja, które również zainspirowane są
przyrodą. W każdym pokoleniu powstaje
nowy zespół sztucznych organizmów, utworzonych z połączenia fragmentów najlepiej przystosowanych
przedstawicieli poprzedniego pokolenia. Oprócz tego sporadycznie wyporóbowuje się nową część 
składową. Element losowości nie oznacza że algorytmy genetyczne sprowadzają się do zwykłego
błądzenia przypadkowego. Dzięki wykorzystaniu przeszłych doświadczeń algorytm określa nowy obszar
poszukiwań o spodziewanej podwyższonej wydajności.
Algorytm genetyczny jest przykładem procedury używającej wyboru losowego jako 
"przewodnika" w wysoce ukierunkowanym poszukiwaniu w zakodowanej przestrzeni rozwiązań
\cite{goldberg}.\\

Poniżej znajduję się podstawowy algorytm genetyczny przedstawiony w postaci
pseudokodu \cite{ams}:\\
\begin{algorithm}[H]
 \SetAlgoLined
 \KwIn{Funkcja oceny $f(\vec{x})$}
 \KwData{$\vec{x}_i(t)$ - $i$-ty osobnik z generacji nr. $t$(najczęściej reprezentowany jako
 	 ciąg znaków), $n_x$ - wymiar każdego osobnika}
 \KwOut{Wektor $\hat{\vec{x}}$ dla którego $f(\hat{\vec{x}})$ jest lokalnym minimum}
 Niech $t = 0$ będzie licznikiem generacji. 
 Wygeneruj $n_x$ - wymiarową populację $\mathcal{C}(0)$, składającą się z n osobników.\\
 \While{Warunek końcowy nie jest prawdziwy}{
	Oblicz przystosowanie, $f(\vec{x}_i(t))$ każdego osobnika $\vec{x}_i(t)$ z populacji.\\
	W celu stworzenia potomstwa do najlepiej przystosowanych osobników zastosuj operatory
	genetyczne np. krzyżowanie i mutacja.\\
	Z nowo powstałych osobników stwórz nową populację $\mathcal{C}(t + 1)$.\\
	Przejdź do nowej generacji. $t = t + 1$.\\
 }
 \caption{Podstawowy Algorytm genetyczny}
\end{algorithm}

\subsubsection{Podstawowa reprezentacja}
Jednym z następstw inspiracji biologicznych AG jest słownictwo zaczerpnięte 
z genetyki którym będę się posługiwać w tej pracy.
Osobniki występujące w populacji nazywane są \textbf{chromosomami} lub \textbf{genomami}.
Idąc dalej w terminologii biologicznej chromosom składa się z \textbf{genów}, które mogą
występować w pewnej zadanej liczbie odmian, zwaną \textbf{allelami}, wyodrębnia się również
umiejscowienie genu - \textbf{locus}.
Materiał genetyczny składa się zazwyczaj z jednego lub więcej chromosomów, zespół ten nazywamy
\textbf{genotypem}\cite{goldberg}.
Poniższa tabela przedstawia używane przeze mnie odpowiedniki:
\begin{center}
\begin{tabular}{|c|c|}
	\hline
	Genetyka & Algorytmy Genetyczne\\
	\hline
	chromosom/genom & osobnik w populacji\\
	gen & składowe osobnika\\
	allel & możliwe warianty składowych\\
	locus & pozycja składowej\\
	genotyp & zespół osobników\\
	\hline
\end{tabular}
\end{center}

W elementarnym AG \textbf{genom} reprezentujemy za pomocą ciągów bitów, więc \textbf{genami}
będą pojedyncze bity.
Poniżej znajduję się przykładowy genom:\\

\begin{figure}[H]
\centering
\includegraphics[scale=0.20]{genome_v2.png}
\caption{Przykładowy genom o długości 10.}
\end{figure}

Transformacja naszego problemu do opisu w postaci ciągów binarnych jest często bardzo trudne, a
czasami wręcz niemożliwa. Lecz trud ten jest opłacalny ponieważ dla tak opisanych genomów mamy
zdefiniowane operatory genetyczne które wykonując proste obliczenia zbliżają nasze osobniki do
optymalnego rozwiązania.

\subsubsection{Selekcja}
Jest to etap algorytmu w którym oceniamy osobników przy pomocy funkcji określonej przez
rozwiązywany przez nas problem, a następnie lepiej ocenione chromosomy mają większe 
prawdopodobieństwo aby zostały poddane operatorom genetycznym.
Aby opisać ten proces musimy zdefiniować przedstawioną w \textbf{Algorytmie 1} funkcję oceny 
$f$.\\
\textbf{Funkcja oceny/przystosowania} $f$ jest obliczana dla każdego osobnika i pozwala nam
porównać które genomy są najlepiej przystosowane do zadania które optymalizujemy.\\
Najprostszym przykładem będzie zadanie znalezienia maximum funkcji 
$f(x_1, ..., x_n)$ gdzie $n \in \mathbb{N}^{+}$, wtedy funkcja przystosowania
będzie równa wartości funkcji $f$, im większa wartość $f$ tym osobnik jest
lepiej przystosowany.\\\\
Istnieje wiele metod selekcji lecz zdecydowanie najpopularniejszą jest \textbf{metoda ruletki}
w której prawdopodobieństwo $p_i$
wybrania $i$-tego genomu do reprodukcji kolejnego pokolenia jest proporcjonalne do wartości
funkcji przystosowania i jest równe:
\begin{equation}
	p_i = \frac{f_i}{\sum_{j=1}^{N} f_j}
\end{equation}
gdzie:\\
$f_i$ - wartość funkcji oceny dla $i$-tego genomu, $N$ - rozmiar populacji.\\

\subsubsection{Krzyżowanie}
Jednym z dwóch podstawowych operacji wykonywanych w celu stworzenia potomstwa obecnej populacji
jest \textbf{krzyżowanie}, które inspiruję się rozmnażaniem płciowym w biologi \cite{cross}.

W literaturze możemy znaleźć wiele rodzajów tej operacji, poniżej znajdują się najpopularniejsze
odmiany:
\begin{itemize}
\item \textbf{Krzyżowanie jednopunktowe}:\\
W tej odmianie potomka tworzymy z dwóch wybranych przez selekcję rodziców a następnie 
losujemy liczbę naturalną  $l$ ze zbioru $\{0,1,\ldots, n_x\}$.
Potomek wartości na pierwszych $l+1$ pozycjach przyjmuje geny pierwszego rodzica
a na pozostałych z drugiego rodzica.
\begin{figure}[H]
\centering
\includegraphics[scale=0.2]{crossover_v2.png}
\caption{Krzyżowanie jednopunktowe, gdzie $n_x = 10$ i $l = 5$.}
\end{figure}

\item \textbf{Krzyżowanie dwupunktowe}:\\
Sposób ten jest zbliżony do opisanego wyżej lecz zamiast jednego punktu losujemy dwie liczby
naturalne $l_1, l_2$ ze zbioru $\{0,1,\ldots, n_x\}$, gdzie $l_1 < l_2$.
Potomek natomiast przyjmuje wartości z pierwszego rodzica poza elementami na pozycjach od
$l_1$ do $l_2 - 1$ gdzie wstawiamy elementy z drugiego.

\begin{figure}[H]
\centering
\includegraphics[scale=0.2]{two_crossover_v2.png}
\caption{Krzyżowanie dwupunktowe, gdzie $n_x = 10$, $l_1 = 4$ i $l_2 = 7$.}
\end{figure}

Krzyżowania tego rodzaju można uogólnić na operacje gdzie losujemy k-punktów
a potomek naprzemiennie pobiera wartości z rodziców.\\
\item \textbf{Krzyżowanie równomierne}:\\
Potomek jest również tworzony przy pomocy dwóch rodziców gdzie każdy jego element jest
wybierany losowo z pierwszego lub drugiego rodzica z jednakowym prawdopodobieństwem 
(lub wybranym innym stosunkiem prawdopodobieństw).

\end{itemize}

\subsubsection{Mutacja}
Operator ten w klasycznej wersji algorytmu polega na zamianie zadanej wartości genu
(0 na 1 lub 1 na 0) z bardzo małym  prawdopodobieństwem $\sigma_m$(np. 0.2\%).
\begin{figure}[H]
\centering
\includegraphics[scale=0.2]{mutation_v2.png}
\caption{Podstawowa mutacja dla genomu o $n_x = 10$ i wylosowanej pozycji 6.}
\end{figure}



\subsection{Sztuczne Sieci Neuronowe}
Podobnie jak dla Algorytmów Genetycznych, inspiracją dla Sztucznych Sieci Neuronowych (SSN) 
byłą biologia a dokładniej budowa neuronów naturalnych znajdujących się w ciele człowieka.
Sztuczne sieci neuronowe zostały wymyślone już w w pierwszej połowie XX wieku, lecz dopiero w ostatnich latach
dzięki rozwojowi technologi oraz dostępności do olbrzymiej ilości danych mogliśmy zacząć używać
ich pełnego potencjału. SSN są przykładem techniki \textbf{uczenia nadzorowanego} tzn.
podczas uczenia sieci podajemy mu dane ze znanymi wynikami i poprzez porównywanie wygenerowanych
wyników z rzeczywistymi nasza sieć uczy się generować poprawne wyniki.

\subsubsection{Perceptron}
\textbf{Perceptron} to  najprostsza architektura SSN. Jednostki na wyjściach/wejściach
nazywane są \textbf{neuronami}. Na neuronach wejściowych  podawane są liczby oraz
każde połączenie ma przypisaną  wagę natomiast wyjście perceptronu jest obliczane przez 
wyliczenie ważonej sumy sygnałów wejściowych:
\begin{equation}
	z = \sum_{i=1}^n w_ix_i = \vec{w}^T\vec{x}
\end{equation}
gdzie:\\
$w_i$ - waga połączenia pomiędzy $i$-tym neuronem wejściowym a $j$-tym wyjściowym,\\
$x_i$ - $i$-ta wartość wejściowa.\\ \\
Następnie wynik otrzymany w (2) jest poddawany \textbf{funkcji skoku}, gdzie najczęściej jest 
ona równa \textbf{funkcji Hraviside'a} lub \textbf{signum} które są równe:
\[
	\text{Heaviside}(z) = \
	\begin{cases}
		0, \: z < 0 \\
		1, \: z \geq 0
	\end{cases} 
	\text{sgn}(z) = \
	\begin{cases}
		-1, \: z < 0 \\
		0, \: z = 0 \\
		1, \: z > 0
	\end{cases} 
\]
Nazywane są one \textbf{funkcjami aktywacji}.\\

\begin{figure}[H]
\centering
\includegraphics[scale=0.5]{perceptron.png}
\caption{Schemat perceptronu z jednym neuronem wyjściowym i trzema wejściowymi \cite{um}}
\end{figure}

Lecz aby na wyjściu otrzymywać oczekiwane wyniki musimy najpierw perceptron wytrenować. Proces
ten polega na modyfikacji wag na podstawie porównanie wyniku oczekiwanego z wynikiem otrzymanym.
Wagi są aktualizowane według wzoru \cite{um}:
\begin{equation}
	w_{ij} = w_{ij} + \eta(y_j - \hat{y_j})x_i
\end{equation}
gdzie:\\
$w_{ij}$ - waga połączenia pomiędzy $i$-tym neuronem wejściowym a $j$-tym wyjściowym,\\
$\hat{y_j}$ - otrzymany wynik na $j$-tym wyjściu,\\
$y_j$ - docelowy wynik $j$-tego neuronu,\\
$\eta$ - współczynnik uczenia.\\
Perceptron jednak nie nadaje się do skomplikowanych zadań ponieważ przez swoją prostą budowę
jest jedynie zdolny do klasyfikowania danych które są liniowo separowalne.

\subsubsection{Wielowarstwoa Sieć Neuronowa}
Ograniczenia perceptronu można wyeliminować tworząc SSN z wielu warstw perceptronów.
SSN tego typu nazywamy \textbf{perceptronem wielowarstwowym}, który jest złożony z 
\textbf{warstwy wejściowej}, co najmniej jednej \textbf{warstwy ukrytej} (jako wejście przyjmują
one wyjście poprzedniej warstwy a ich wyjście propagowane do kolejnej jako wejście) ostatnią
warstwę nazywamy \textbf{warstwą wyjściową}. Dodatkowo w każdej warstwie znajduję się 
\textbf{neuron obciążający}, którego zadaniem jest wysyłanie na wejście następnej warstwy 
wartości 1. Ilość neuronów w warstwie wejściowej i wyjściowej jest określana przez
zestaw danych na których sieć ma pracować np. jeśli zadaniem sieci jest rozpoznawanie
ręcznie pisanych cyfr to na wyjściu powinno znaleźć się 10 neuronów a na wejściu każdy neuron
powinien odpowiadać jednemu pikselowi wczytanego obrazu.
SSN która zawiera co najmniej dwie warstwy ukryte nazywamy
\textbf{głęboką siecią neuronową} (GSN) \cite{um}.

\begin{figure}[H]
\centering
\includegraphics[scale=0.5]{gsn.png}
\caption{Perceptron wielowarstwowy z jedną warstwą ukrytą \cite{um}.}
\end{figure}

Zaproponowana w wzorze (3) metoda uczenia perceptronu nie zadziała w przypadku sieci
wielowarstwowej. Najpopularniejszą metodą uczenia sieci neuronowych 
jest \textbf{wsteczna propagacja}. Cały proces możemy przedstawić za pomocą kroków:

{\LinesNumbered
\begin{algorithm}[H]
 Wybór parametrów sieci (liczba warstw, liczba neuronów w warstwach itd.)\\
 Wagi inicjujemy losowo.\\
 Dla każdego neuronu obliczany jest błąd równy różnicy pomiędzy otrzymanym
 wynikiem $\hat{\vec{y}}$ a wartością oczekiwaną $\vec{y}$.\\
 Błędy propagowane są do poprzednich warstw.\\
 Modyfikacja wag na podstawie wartości błędu.\\
 Powtarzaj od \textbf{3} dla kolejnych wektorów uczących.\\
 Skończ algorytm jeśli przekroczymy ustaloną liczbę epok, lub średni błąd przestanie zauważalnie
 maleć.\\
 \caption{Procedura uczenia wielowarstwowej SSN.}
\end{algorithm}}
Średni błąd może być przestawiony przez wzór:
\begin{equation}
	d = \frac{1}{2}(\hat{\vec{y}} - \vec{y})^2
\end{equation}
Podczas aktualizowania wag wybieramy te wartości dla których średni błąd jest najmniejszy, możemy
je znaleźć np. używając metodę gradientu prostego przy użyciu odwrotnego różniczkowania
automatycznego.

\subsubsection{Funkcje aktywacyjne}
Aby powyższy algorytm przebiegał prawidłowo zamiast funkcji skokowej/signum wprowadzono inne 
funkcje aktywacji, ponieważ funkcje używane w przypadku pojedynczego perceptronu są złożone
jedynie z płaskich segmentów, co uniemożliwia korzystać z gradientu. Poniżej znajdują się 
najczęściej używane \textbf{funkcje aktywacji} w SSN:
\begin{itemize}
\item \textbf{funkcja logistyczna}:\\
W każdym punkcie ma zdefiniowaną pochodną niezerową, dzięki czemu algorytm gradientu prostego
może na każdym etapie uzyskiwać lepsze wyniki. Jest ona używana w warstwie wyjściowej jeśli
zadaniem naszej sieci jest klasyfikacja obiektów na przynależność do dwóch rozłącznych klas.
Dodatkowo jest to funkcja używana przez neurony 
naturalne przez co uważana była za najlepszą funkcję aktywacyjną, lecz jak pokazała praktyka
w przypadku SSN inne funkcje sprawują się lepiej. Przyjmuje ona wartości z zakresu $(0,1)$.
\begin{equation}
\sigma(z) = \frac{1}{1 + e^{-z}}
\end{equation}
\item \textbf{funkcja tangensa hiperbolicznego}:\\
Jest S - kształtna, ciągła i różniczkowalna, podobnie jak funkcja logistyczna, 
ale zakres wartości wynosi $(-1, 1)$ a nie $(0, 1)$ ja w przypadku funkcji logistycznej
$\sigma$.
\begin{equation}
	\tanh(z) = \frac{e^z - e^{-z}}{e^z + e^{-z}}
\end{equation}
\item \textbf{funkcja ReLU}:\\
Jest ciągłą, ale nieróżniczkowalna dla $z = 0$. W praktyce jednak spisuje się znakomicie 
dodatkowo jest bardzo szybko obliczana. Aktualnie jest ona oraz jej odmiany są najczęściej
używanymi funkcjami aktywacji dla warstw ukrytych i wejściowej. 
\begin{equation}
	ReLU(z) = \max(0, z)
\end{equation}
\item \textbf{funkcja softmax}:\\
Używana jest ona w warstwie wyjściowej jeśli nasza sieć ma obliczać
prawdopodobieństwa przynależności otrzymywanych obiektów  do klas 
(jest ich więcej niż 2 i wszystkie prawdopodobieństwa mają się sumować do $1$).
Model najpierw oblicza dla każdej klasy - $k$:
\begin{equation}
	s_k(\vec{x}) = \big(\vec{w}^{(k)}\big)^T\vec{x}
\end{equation}
gdzie: $\vec{w}^{(k)}$ - wyspecjalizowany wektor wag dla klasy $k$.\\
Po wyliczeniu $s_k(\vec{x})$ dla każdej klasy, obliczane jest odpowiednio znormalizowane 
prawdopodobieństwo przynależności danej próbki do klasy $k$:
\begin{equation}
	p_k = \frac{\exp\big(s_k(\vec{x})\big)}{\sum_{i=1}^{K} \exp\big(s_i(\vec{x})\big)}
\end{equation}
gdzie: $K$ - liczba klas.\\ 
Model prognozuje klasę o najwyższym prawdopodobieństwie:
\begin{equation}
	\hat{y} = \underset{k}{\text{argmax}}(p_k)
\end{equation}
Gdzie funkcja \textbf{argmax} zwraca indeks klasy dla której wartość $p_k$ jest największa.\\
\end{itemize}

\begin{figure}[H]
\centering
\includegraphics[scale=0.6]{f_a.png}
\caption{Funkcje aktywacyjne i ich pochodne. \cite{um}}
\end{figure}

\subsubsection{Inne rodzaje warstw SSN.}
W SSN oprócz \textbf{warstw gęstych} tzn.
gdzie każdy neuron w $i$-tej warstwie jest połączony z wszystkimi neuronami
znajdującymi się w warstwie nr. $i+1$,
używane są warstwy innego typu które pomagają siecią
osiągać lepsze wyniki. Oto kilka przykładowych warstw:
\begin{itemize}
\item \textbf{warstwa splotowa}:
Używane są one w zadaniach wizualnych. Neurony w pierwszej warstwie splotowej nie są
połączone z każdym pikselem obrazu wejściowego, lecz wyłącznie z pikselami
znajdującymi się w ich polu recepcyjnym.

\begin{figure}[H]
\centering
\includegraphics[scale=0.6]{cnn.png}
\caption{Warstwy CNN z prostokątnymi lokalnymi polami recepcyjnymi \cite{um}.}
\end{figure}

Dzięki powyższej strukturze sieć może koncentrować się na ogólnych cechach w pierwszej warstwie
ukrytej, następnie łączyć je w bardziej złożone kształty w kolejnych warstwach. Ogólnie neuron
znajdujący się w $i$-tym wierszu oraz $j$-tej kolumnie danej warstwy jest połączony z wyjściami 
neuronów poprzedniej warstwy zlokalizowanymi w rzędach od $i \cdot s_h$ do 
$i \cdot s_h + f_h-1$  i kolumnach
od $j \cdot s_w $ do $j \cdot s_w + f_w-1$
gdzie: $f_w/f_h$ - szerokość/wysokość pola recepcyjnego, $s_h, s_w$ definiują wartość 
\textbf{kroków} odpowiednio w kolumnach i rzędach. \textbf{Krokiem} nazywamy odległość
pomiędzy dwoma kolejnymi polami recepcyjnymi. Aby uzyskać takie same wymiary 
dla każdej warstwy najczęściej dodawane są zera wokół wejść.\\

Wagi neuronu mogą być przedstawione jako niewielki obraz o rozmiarze pola recepcyjnego, tak 
zwane \textbf{filtry}. Przykładowo filtrem może być macierz wypełniona zerami oprócz środkowej
kolumny zawierającej jedynki, neurony posiadające taki filtr będą ignorować wszystkie elementy
oprócz tych które znajdują się w środkowej linii.

\begin{figure}[H]
\centering
\includegraphics[scale=0.6]{filtr.png}
\caption{Dwie mapy cech otrzymane przy pomocy dwóch różnych filtrów \cite{um}.}
\end{figure}

Warstwa wypełniona neuronami o takim
samym filtrze nazywamy \textbf{mapą cech} która pomaga nam wyszczególnić elementy przypominające
użyty filtr. Warstwa splotowa składa się z kilku map cech o identycznych rozmiarach.
Każda mapa ma swoje wartości parametrów, dzięki czemu stosując różne filtry 
warstwa splotowa jest w stanie wykryć wiele cech w dowolnym obszarze obrazu.
Dodatkowo obrazy wejściowe składają się również z kilu warstw, po jednej na każdy kanał
barw. Zazwyczaj są to trzy kanały - czerwony, zielony i niebieski lub jeden dla obrazów
czarno-białych.


\begin{figure}[H]
\centering
\includegraphics[scale=0.6]{rgb_cnn.png}
\caption{Warstwa splotowa zawierająca wiele cech, oraz zdjęcie z trzema kanałami barw \cite{um}.}
\end{figure}

\item \textbf{warstwa łącząca}:
Jej celem jest zmniejszenie obrazu wejściowego w celu zredukowania obciążenia obliczeniowego,
wykorzystania pamięci i liczby parametrów. Tak samo jak w warstwach splotowych neurony 
łączą się z wyjściami określonej liczby neuronów poprzedniej warstwy, które mieszczą się w
obszarze pola recepcyjnego. Jednakże warstwa ta nie zawiera wag, jej zadaniem jest gromadzenie
danych przy pomocy funkcji agregacyjnej np. maksymalizującej lub uśredniającej.

\begin{figure}[H]
\centering
\includegraphics[scale=0.6]{pool.png}
\caption{Maksymalizująca warstwa łącząca, gdzie rozmiar jądra łączącego to 2x2 \cite{um}.}
\end{figure}

\item \textbf{warstwa porzucania}:\\
Warstwa ta dla poprzedniej warstwy aplikuję technikę \textbf{porzucania} tzn. że
każdy neuron znajdujący się w tej warstwie w poszczególnym przebiegu może zostać całkowicie
pominięty w procesie uczenia. Szansa na porzucenie jest hiperparametrem i nazywana jest 
\textbf{współczynnikiem porzucenia}.

\begin{figure}[H]
\centering
\includegraphics[scale=0.6]{dropout.png}
\caption{Przykład porzucania \cite{um}.}
\end{figure}

\end{itemize}
Istnieje wiele innych rodzajów warstw w SSN (np. rekurencyjne) lecz opisałem tyko warstwy
użyte w moim programie. Z tego samego powodu jedyną opisaną przeze mnie architekturą jest
\textbf{jednokierunkowa sieć neuronowa}(sygnał biegnie w jednym kierunku).

\section{Micro - GA dla SSN}
SSN posiadają dużą liczbę hiperparametrów i wpływ każdego z nich na efektywność sieci jest
zależny od wykonywanego zadania, więc jeżeli wybieramy je ręcznie musimy to robić
metodą prób i błędów. Aby użyć AG to tego zadania musimy zmodyfikować jego tradycyjną odmianę.
Ponieważ zależy nam na szybkości wykonywanych obliczeń zastosowana została odmiana 
\textbf{micro-GA} gdzie liczba dozwolonych generacji jest niewielka. Dodatkowo aby przyśpieszyć
działanie algorytmu SSN są trenowane przez ograniczoną liczbę epok tzw. \textbf{uczenie
częściowe}.

\begin{algorithm}[H]
 \SetAlgoLined
 \KwData{Treningowy i walidacyjny zbiór danych $\mathcal{D}_t$, $\mathcal{D}_v$}
 \KwIn{Parametry algorytmu.}
 \KwOut{Najlepiej przystosowana SSN $\phi^{*}$}
 \caption{Zmodyfikowany Algorytm Genetyczny wybierający hiperparametry SSN.}
 Niech $t_e = 0$ będzie licznikiem wykonanych przebiegów AG.\\
 Niech $\mathcal{S} = \{\}$ zbiór na najlepsze rozwiązania.\\
 \While{$t_e < \gamma_r$}{
 	Niech $t = 0$ będzie licznikiem generacji.\\
	Stwórz i losowo zainicjalizuj początkową populację $\mathcal{C}(0)$, zawierającą 
	$n$ osobników, gdzie $n \leq 10$.\\
	\While{$t<\gamma_g \lor$ warunek wczesnego ko\'nca dla $\mathcal{C}(t)$ nie 
	       jest spełniony}{
		Oblicz funkcję przystosowania $f(\phi)$ dla każdego osobnika w populacji.\\
		Zastąp najgorsze modele w $\mathcal{C}(t)$ najlepszymi modelami 
		$\mathcal{C}(t-1)$.\\
		Wykonaj selekcję tworząc populację potomstwa $\mathcal{O}(t)$.\\
		Wykonaj operację krzyżowania i mutacji na osobnikach z $\mathcal{O}(t)$.\\
		$\mathcal{C}(t + 1) = \mathcal{O}(t)$.\\
		$t = t + 1$.\\
	}
	Do $\mathcal{S}$ dodaj najlepszego osobnika z poprzedniego przebiegu.\\
	$t_e = t_e + 1$.\\
  }
  Znormalizuj koszt dla każdego modelu w $\mathcal{S}$.\\
  Najlepszym modelem jest osobnik z $\mathcal{S}$ dla którego funkcja przystosowania
  przyjmuję najniższą wartość.
\end{algorithm}
Poniżej znajduję się lista parametrów powyższego algorytmu oraz użyte dla nich oznaczenia
ich rola natomiast zostanie omówiona w kolejnych podrozdziałach.\\
\begin{center}
\begin{tabular}{|c|c|}
	\hline
	Nazwa parametru & Oznaczenie \\
	\hline
	Współczynnik sprawdzianu krzyżowego & $\gamma_v$ \\
	Prawdopodobieństwo mutacji & $\rho_m$ \\
	Prawdopodobieństwo dodania warstwy & $\gamma_l$ \\
	Maksymalna liczba warstw & $\mathcal{A}$ \\
	Współczynnik skalowania rozmiaru sieci & $\alpha$ \\
	Rozmiar populacji & $n$ \\
	Rozmiar turnieju & $n_t$ \\
	Dopuszczalne podobne modele & $\gamma_c$\\
	Liczba epok treningowych & $\gamma_t$\\
	Liczba generacji & $\gamma_g$\\
	Liczba eksperymentów & $\gamma_r$\\
	\hline
\end{tabular}
\label{tab:ag}
\newline
\end{center}

\subsection{Reprezentacja SSN w AG}
Z powodu złożoności SSN musiałem zrezygnować ze standardowej reprezentacji osobników 
jako ciągi binarne. Użytym przeze mnie modelem jest kodowanie oparte na liście tablic tzn.
każda warstwa sieci jest reprezentowana jako tablica w której każde pole ma z góry określone 
znaczenie. W tej reprezentacji warstwy przyjmują postać:\\
\begin{figure}[H]
\centering
\includegraphics[scale=0.30]{dnn_genome.png}
\caption{Schemat chromosomu reprezentującego SSN.}
\end{figure}
Gdzie każde pole może przyjmować pewien zakres wartości:\\
\begin{center}
\begin{tabular}{|c|c|c|}
	\hline
	Nr. & Używane Przez & Wartości \\
	\hline
	1 & Perceptron wielowarstwowy/Sieć splotowa & $x \in \{1, ...,4\}$\\
	2 & Perceptron wielowarstwowy & $8*x$ dla $x\in \{1, ...,128\}$\\
	3 & Perceptron wielowarstwowy/Sieć splotowa & $x \in \{1, ...,4\}$\\
	4 & Sieć splotowa & $8*x$ dla $x\in \{1, ...,64\}$\\
	5 & Sieć splotowa & $3^x$ dla $x \in \{1, ...,6\}$\\
	6 & Sieć splotowa & $x \in \{1, ...,6\}$\\
	7 & Sieć splotowa & $2^x$ dla $x \in \{1, ...,6\}$\\
	8 & Perceptron wielowarstwowy/Sieć splotowa & $x \in [0, 1]$\\
	\hline
\end{tabular}
\label{tab:params}
\end{center}

Osobniki więc będą listą takich tablic.
Warstwa wejściowa i wyjściowa jest ustalona 
przez zadanie jakie ma wykonywać sieć np. jeśli trenowana sieć ma rozpoznawać ręcznie pisane
cyfry wiemy że w warstwie  wyjściowej musi pojawić się 10 neuronów z funkcją aktywacyjną
typu softmax.
Generując jednak pozostałe warstwy musimy pamiętać że warstwy nie mogą być ułożone losowo
(np. nie mogą występować dwie warstwy porzucania po sobie). Poniżej znajdują się odpowiednie
mapowania typów warstw i funkcji aktywacji na liczby całkowite oraz odpowiednie zasady 
łączenia warstw w budowanych osobnikach.\\

\begin{center}
\begin{tabular}{|c|c|c|}
	\hline
	Typ warstwy & Nazwa & Dozwoleni następcy \\
	\hline
	1 & Warstwa Gęsta & 1, 4\\
	2 & Splotowa & 1, 2, 3, 4\\
	3 & Łącząca & 1, 2\\
	4 & Porzucenia & 1, 2 \\
	\hline
\end{tabular}
\label{tab:rules}
\end{center}
\begin{center}
\begin{tabular}{|c|c|}
	\hline
	Typ funkcji & Nazwa\\
	\hline
	1 & Sigmoid \\
	2 & Tangens hiperboliczny \\
	3 & ReLU \\
	4 & Softmax \\
	5 & Liniowa \\
	\hline
\end{tabular}
\end{center}

Dodanie innych typów warstw (np. rekurencyjnych) i funkcji nie powinno być problemem, jedynie
trzeba pamiętać o dodaniu odpowiednich zasad budowania dla nich.
Przykładowy genomem reprezentującym SSN jest:\\
\begin{center}

	$\big[$[1, 784, 3, 0, 0, 0, 0, 0], [4, 0, 0, 0, 0, 0, 0, 0.54], 
	\newline 
	\quad [1, 300, 3, 0, 0, 0, 0, 0], [4, 0, 0, 0, 0, 0, 0, 0.28], 
	\newline 
	[1, 100, 3, 0, 0, 0, 0, 0], [1, 10, 4, 0, 0, 0, 0, 0]$\big]$
	\newline

\end{center}
Dekodując powyższy gneom otrzymujemy sieć złożoną z następujących warstw:\\
\begin{center}
\begin{tabular}{|c|c|c|c|}
	\hline
	Typ warstwy & Liczba Neuronów & Funkcja Aktywacji & Wsp. Porzucenia \\
	\hline
	Gęsta & 784 & ReLU & N/A \\
	Porzucanie & N/A & N/A & 0.54\\
	Gęsta & 300 & ReLU & N/A \\
	Porzucanie & N/A & N/A & 0.28\\
	Gęsta & 100 & ReLU & N/A \\
	Gęsta & 10 & Softmax & N/A \\
	\hline
\end{tabular}
\end{center}


\subsection{Generowanie w populacji początkowej}
Generując genomy w populacji warstwa pierwsza wyznacza typ SSN(np. jeśli pierwszą warstwą
jest warstwa gęsta to sieć będzie perceptronem wielowarstwowym, a jeśli pierwszą warstwą
będzie warstwa splotowa sieć będzie siecią splotową).
Warstwa wejściowa i wyjściowa dla każdego osobnika jest taka sama ponieważ
są one zależne od danych na jakich trenujemy oraz od zadania jakie ma nasza sieć wykonywać
(klasyfikacja lub regresja), dlatego w populacji początkowej musimy losowo generować tylko
warstwy ukryte.
Proces generowania możemy określić przy pomocy pseudokodu:\\
\newline
\begin{algorithm}[H]
	\KwOut{Zainicjalizowana populacja początkowa $\mathcal{C}(0)$.}
	Niech $\mathcal{C}(0)$ oznacza populację początkową wielości
	$n$, gdzie chromosomy tej populacji możemy oznaczyć przez $\vec{x}_i$.\\
	\For{Dla każdego i, gdzie $1 \leq i \leq$ $n$} {
		Dla wszystkich warstw poza wyjściową (która ma z góry określoną 
		funkcję aktywacji) losujemy funkcję aktywacji $f$.\\
		\While{Liczba warstw $\vec{x_i} \leq \mathcal{A}$} {
			Wylosuj typ warstwy a następnie wartości używanych przez nią 
			parametrów.\\
			Wylosuj liczbę $U$ przy pomocy płaskiego rozkładu prawdopodobieństwa
			z przedziału $[0, 1]$.\\
			Oblicz $\rho_l = 1 - \sqrt{1 - U}$.\\
			\If{$\rho_l < \gamma_l$}{
				Jeśli wygenerowana warstwa jest kompatybilna w warstwą
				poprzednią dodaj ją do chromosomu.\\
			}
			\Else{
				Kończymy dodawanie warstw dla $\vec{x}_i$.\\
			}
		}
	}
	\caption{Generowanie populacji początkowej.}
\end{algorithm}

\subsection{Funkcja oceny dla SSN}
Celem algorytmu jest znalezienie sieci $\phi^{*}$ osiągającej jak najlepszy wynik jednocześnie
ograniczając liczbę trenowalnych parametrów, więc jest to problem optymalizacyjny 
przedstawiony za pomocą wzoru:
\begin{equation}
	\underset{\phi}{\min}\big(p(\phi), w(\phi)\big)
\end{equation}
gdzie:\\
$p(\phi)$ - miara jakości sieci(np. błąd predykcji),\\
$w(\phi)$ - liczba trenowalnych parametrów zwana \textbf{rozmiarem sieci}.\\
Jeżeli jednak chcielibyśmy znaleźć bezpośrednio rozwiązanie powyższego równania
prowadziłoby to do zadania optymalizacji wielokryterialnej. Aby uprościć to zadanie
definiujemy funkcję oceny, względem której osobniki w populacji będą porównywane:
\begin{equation}
	g(\phi) = (1 - \alpha)p(\phi) + \alpha w(\phi)
\end{equation}

Jednak powinniśmy jeszcze przeskalować $p(\phi)$, $w(\phi)$ aby ich wartości były podobnego 
rzędu. Niech $\vec{p} = \{p(\phi_1), ..., p(\phi_n)\}$ będzie wektorem ocen aktualnej populacji,
wtedy po znormalizowaniu $\vec{p}^{*} = \frac{\vec{p}}{||\vec{p}||}$ zakres wartości ocen sieci
będzie z przedziału $p^{*}(\phi_i) \in [0, 1]$ dla każdego $i$. Niech $\mathcal{A}$ oznacza
maksymalną liczbę warstw w sieci, oraz $\mathcal{N}$ oznacza maksymalną liczbę neuronów w 
warstwie wtedy maksymalna wartość rozmiaru sieci jest równa $w(\phi) = \mathcal{N}^2\mathcal{A}$.
Ponieważ chcemy aby sieci o podobne rozmiarowi sieci miały podobną wartość $w(\phi)$ dlatego
ostatnie trzy cyfry rozmiaru na zera otrzymując $w'(\phi)$. Następnie aby skalami zbliżyć się do 
wartości ocen w tym celu wyznaczamy $w^{*}(\phi) = \log_{10}w'(\phi)$ (rozmiaru sieci
nie normalizujemy podobnie jak wartości ocen ponieważ chcemy aby różnica w rozmiarze
miała większe wpływ na różnice w funkcji ocen), co nam daję wartości
rzędu $\log_{10}(\mathcal{N}^2\mathcal{A})$.\\
Wtedy odpowiednio przeskalowana funkcja oceny wyrażona jest wzorem:
\begin{equation}
	g(\phi) = \log_{10}(\mathcal{N}^2\mathcal{A})(1 - \alpha)p^{*} + \alpha w^{*}(\phi)
\end{equation}

\subsection{Selekcja}
Aby wygenerować $n$ potomków potrzebujemy $2n$ rodziców wybranych z bieżącej populacji.
Do tego celu wykonamy odmianę \textbf{binarnej selekcji turniejowej}:\\
\begin{algorithm}[H]
 \KwIn{Aktualna generacja $\mathcal{C}(t)$.}
 \KwOut{Najlepiej przystosowani osobnicy z populacji.}
 Niech $\mathcal{P}$ - zbiór rodziców.\\
 Wybierz losowo $m$ rodziców gdzie $m < n$.\\
 \While{nie wybrano 2n rodziców} {
	Porównaj parami wybrane genomy, lepiej przystosowany dodaj do $\mathcal{P}$.\\
 }
 \caption{Binarna selekcja turniejowa dla SSN.}
\end{algorithm}
W powyższej procedurze im większa wartość $m$ tym większe jest prawdopodobieństwo wybrania
najlepszych osobników jako rodzica.

\subsection{Krzyżowanie}
Ponieważ standardowe operatory genetyczne nie będą działać dla zmodyfikowanego kodowania
genomów, je również trzeba zmodyfikować. Wybranym krzyżowaniem jest zmodyfikowane krzyżowanie
dwupunktowe. Wykonując krzyżowanie musimy pamiętać, że nie każda warstwa może występować po 
każdej innej. Przykładowa dla dwóch rodziców $S_1$, $S_2$ po wybraniu punktów $(r_1, r_2)$ z 
$S_1$ i $(r_3, r_4)$ z $S_4$ (gdzie $r_i$ oznacza indeks warstwy), może się stać że warstwa
$r_3$ nie może być zamieniona z warstwą $r_1$ lub $r_4$ z $r_2$ z powodu niekompatybilności
z warstwą poprzednią \ref{tab:rules}.\\
\begin{algorithm}[H]
	\KwIn{Dwa genomy $S_1$, $S_2$.}
	\KwOut{Nowy potomek $S_3$.}
	Losowo wybierz dwa punkty z $S_1$ gdzie $r_1 \leq r_2$.\\
	\If{$r_1$ = $r_2$} {
		$r_2$ = \text{len}($S_1$) - 1
	}
	Znajdź wszystkie pary punktów $(r_3, r_4)_i$ w $S_2$ kompatybilne z $(r_1, r_2)$,
	gdzie $r_3 < r_4$ i $len(S_1) + (r_4 - r_3) - (r_2 - r_1) < \mathcal{A}$
	(sprawdzamy czy nie przekraczamy maksymalnej liczby warstw).\\
	Losowo wybierz jedną z par $(r_3, r_4)_i$.\\
	W $S_1$ zastąp warstwy z przedziału $[r_1, r_2]$ warstwami z przedziału $[r_3, r_4]$
	wzięte z $S_2$. Nowy genom oznacz jako $S_3$.\\
	W $S_3$ zmień w warstwach wziętych z $S_2$ funkcję aktywacji, na funkcję 
	używaną w warstwach wziętych z  $S_1$.
	\caption{Krzyżowanie dwupunktowe dla SSN.}
\end{algorithm}
Operacja ta dla dwóch poniższych chromosomów będzie przebiegać następująco \cite{ams}:\\
\begin{center}

	$S_1 = \big[$[1, 784, 2, 0, 0, 0, 0, 0], [4, 0, 0, 0, 0, 0, 0, 0.54], 
	            \newline 
	            [1, 300, 2, 0, 0, 0, 0, 0], [4, 0, 0, 0, 0, 0, 0, 0.28], 
		    \newline 
		    [1, 100, 2, 0, 0, 0, 0, 0], [1, 10, 4, 0, 0, 0, 0, 0]$\big]$
	\newline
	\newline
	$S_2 = \big[$[1, 64, 1, 0, 0, 0, 0, 0], [4, 0, 0, 0, 0, 0, 0, 0.22],
		    \newline
		    [1, 333, 1, 0, 0, 0, 0, 0], [1, 420, 1, 0, 0, 0, 0, 0],
		    \newline
		    [1, 77, 1, 0, 0, 0, 0, 0], [4, 0, 0, 0, 0, 0, 0, 0.44],
		    \newline
		    [1, 10, 4, 0, 0, 0, 0, 0]$\big]$
	\newline
\end{center}
Dla $r_1 = 1$ i $r_2 = 3$ zbiór wszystkich możliwych par $(r_3, r_4)_i$ dla $S_1$ i $S_2$ wynosi:
\begin{equation*}
	[(0,2),(0,4),(0,5),(1,2),(1,4),(1,5),(2,4),(2,5),(4,5)]
\end{equation*}
Zakładając że wylosowaliśmy punkty $(2,4)$ potomek $S_3$ po wykonanej operacji krzyżowania
jest równy:
\begin{center}
	$S_3 = \big[$[1, 784, 2, 0, 0, 0, 0, 0], [1, 333, 2, 0, 0, 0, 0, 0], 
	            \newline 
	            [1, 420, 2, 0, 0, 0, 0, 0], [1, 77, 2, 0, 0, 0, 0, 0], 
		    \newline 
		    [1, 100, 3, 0, 0, 0, 0, 0], [1, 10, 4, 0, 0, 0, 0, 0]$\big]$
\end{center}
Jak widzimy funkcje aktywacji w warstwach pobranych z $S_2$ zostały zamienione na funkcję
używaną w $S_1$.\\

\subsection{Mutacja}
Mimo że mutacja nie jest potrzebna w mikro-AG, została ona dodana aby jeszcze bardziej
zróżnicować modele i potencjalnie zwiększyć szanse na otrzymanie lepszych rozwiązań.
Zmodyfikowana operacja mutacji jest bardzo podobna do swojej klasycznej wersji.
Każdy model z populacji potomków może podlec mutacji przy prawdopodobieństwie $\rho_m$, wtedy:
\begin{itemize}
	\item Losowo wybierz jedną z warstw, a następnie zmień jeden z jej używanych parametrów
		zgodnie z tabelą \ref{tab:params}.
	\item Zmień funkcję aktywacji, a następnie skoryguj ją w pozostałych warstwach 
	oprócz ostatniej.
	\item Dodaj warstwę porzucenia jeśli może ona występować po zmienianej warstwie.[tab]
\end{itemize}

\subsection{Warunek końca}
W Algorytmie Genetycznym może dojść do sytuacji w której zmiany w kolejnych pokoleniach są
niezauważalne, wtedy bez konsekwencji można zakończyć aktualny przebieg algorytmu. Możemy to
zaimplementować definiując odpowiedni warunek końca. Warunek ten można oprzeć na funkcji oceny
wiemy jednak że sieci o podobnej strukturze będą miały zbliżone wartości dla tej funkcji.
Dlatego warunek końca możemy oprzeć definiując \textbf{odległość} między genomami mówiąca nam
jak zbliżone są do siebie dwie SSN.\\
Niech $S^{(i)}$ - oznacza $i$-tą warstwę sieci $S$. Wtedy przy założeniu 
len$(S_2) \geq$ len$(S_1)$
odległość $d(S_1, S_2)$ miedzy dwoma genomami reprezentującymi SSN możemy obliczyć według 
algorytmu:

\begin{algorithm}[H]
	\KwIn{Dwa genomy $S_1$, $S_2$.}
	\KwOut{Odległość między $S_1$ a $S_2$.}
	Niech $d = 0$ - odległość między $S_1$ a $S_2$.\\
	\For{Dla każdego i, gdzie $1 \leq i \leq$ len$(S_1)$} {
		$d = d + ||S_2^{(i)} - S_1^{(i)}||$.\\
	}
	\For{Dla każdego i, gdzie len$(S_1) < i \leq$ len$(S_2)$} {
		$d = d + ||S_2^{(i)}||$.\\
	}
	\caption{Odległość między dwoma SSN.}
\end{algorithm}

Dla powyższej definicji $d$ jeśli $S_1 = S_2$ to $d(S_1, S_2) = 0$, wiec pozwala nam ona określić
stopień podobieństwa dwóch osobników.\\
Aktualny przebieg AG kończymy więc gdy co najmniej $m_c$ par spełnia $d(S_1, S_2) \leq d_t$,
gdzie zarówno $d_t$ i $m_c$ są parametrami AG.


\section{Implementacja}
Do zrealizowania opisanego wyżej AG użyłem języka \texttt{python} wraz z biblioteką 
implementującą wiele operacji numeryczny \texttt{numpy}, natomiast do budowania i trenowania
sieci neuronowych wykorzystałem popularną bibliotekę \texttt{tensorflow}. Aby przyśpieszyć
trenowanie sieci wykorzystałem platformę \texttt{Google Colab}, gdzie korzystając z popularnej
formy \texttt{jupyter notebooków} mamy darmowy dostęp przez chmurę do karty graficznej
co znacznie przyśpiesza trenowanie SSN, co znacznie skraca czas wykonania naczego algorytmu.
Algorytm podzieliłem na cztery programy gdzie każdy wykonuję jedną z funkcji:
\begin{itemize}
\item Przechowywanie zasad budowania SSN oraz parametrów potrzebnych do wykonania algorytmu.
\item Dla danego chromosomu budowanie sieci przy pomocy biblioteki \texttt{tensorflow}, oraz
zwrócenie oceny oraz wielkości sieci.
\item Implementacja klasy reprezentującej pojedynczy genom gdzie, która ułatwia implementację
operację związane z AG.
\item Implementacja klasy reprezentującej AG gdzie znajdują się funkcję wykonujące algorytmy
opisane w pseudokodach w rozdziale trzecim.
\end{itemize}
Programy opisane są w poniższych podrozdziałach:\\
\subsection{\texttt{building\_rules.py}}
Jest to plik pomocniczy który zawiera on typy wyliczeniowe np. \texttt{LayerType}
zwiększające czytelność kodu, oraz słowniki które:
\begin{itemize}
\item opisują maksymalne wartości opisane w tabeli \ref{tab:params}.
\item zawierają reguły budowania sieci podane w tabeli \ref{tab:rules}.
\item opisują funkcje aktywacyjne dostępne dla warstwy danego typu.
\end{itemize}
\subsection{\texttt{building\_models.py}}
Program ten zawiera funkcję które dla każdego chromosomu budują sieci neuronowe 
przy pomocy biblioteki \texttt{tensorflow} która w aktualizacji \texttt{2.0}
umożliwia budowanie proste modeli przy pomocy modułu \texttt{keras} więc poszczególne 
rodzaje warstw mają swoje gotowe implementację oraz reguły zaimplementowane w wyżej opisanym
programie dają nam gwarancję że modele te będą poprawne. Algorytm genetyczny posiada wszystkie
potrzebne parametry do przeprowadzenia procesu trenowania i zwrócenia potrzebnych dla niego
wartości tzn oceny wydajności sieci oraz liczby trenowalnych parametrów.
\subsection{\texttt{nn\_genome.py}}
W pliku tym znajduję się klasa opakowująca chromosom przy pomocy listy list.
Język \texttt{python} posiada implementację listy która idealnie nadaję się do AG dla SSN, 
ponieważ może ona zawierać wartości różnego typu więc może ona np. posiadać jednocześnie
pole opisujące liczbę neuronów w warstwie, która jest typu całkowitoliczbowego (\texttt{int}),
oraz pole opisujące współczynnik porzucenia co jest typu zmiennoprzecinkowego 
(\texttt{float}).
\subsection{\texttt{nn\_optimizer.py}}
W pliku tym znajduję się największa liczba operacji przy pomocy klasy \texttt{NNOptimizer}
implementujemy cały przebieg AG. Interfejs tej klasy inspirowałem biblioteką implementującą
algorytmy uczenia maszynowego \texttt{scikit-learn} więc aby przeprowadzić proces poszukiwania
optymalnej sieci neuronowej jedyne co musi zrobić użytkownik to stworzyć instancję podanej
wyżej klasy do której konstruktora musimy podać typ wykonywanego zadania
(klasyfikacja lub regresja) oraz ewentualnie parametry opisane w tabeli 
\ref{tab:ag}, lecz nie jest to obowiązkowe ponieważ posiada ona dla nich wartości domyślne,
następnie cały algorytm genetyczny oraz finalne wytrenowanie otrzymanej sieci z pełną
liczbą epok odbywa się przez wywołanie metody \texttt{fit} która pobiera jako argumenty
dane oraz oczekiwane wartości. Poniżej przykładowe wywołanie programu:\\
\begin{center}
\texttt{\# X, y - wczytane wcześniej dane.\\nn\_optimizer.NNOptimizer.fit(X, y)\\}
\end{center}
Interfejs ten umożliwia rozwiązanie jakiegoś problemu z użyciem uczenia maszynowego
nawet jeśli użytkownik nie posiada wiedzy na temat przebiegu algorytmu który dana klasa 
implementuję.\\
\newline
Aby przyśpieszyć wykonywanie AG możemy w każdej generacji budować i trenować 
modele przy pomocy programu \texttt{building\_models.py} równolegle. Jednak trenowanie tylu
sieci jednocześnie jest procesem potrzebujących wiele zasobów, więc można tę opcję wyłączyć
podając wartość argumentu funkcji \texttt{train\_parallel=False} wywołując funkcję 
\texttt{fit}.
Równoległość zaimplementowałem przy pomocy wbudowanej biblioteki \texttt{python'a}
\texttt{multiprocessig} i jej klasy \texttt{Pool}, która posiada
funkcję \texttt{pool} do której jako argumenty mogę podać funkcję budującą i trenującą 
SSN oraz populację chromosomów, wtedy dla każdego osobnika zostanie utworzony osobny proces
i możliwe będzie ich równoległa ewaluacja.


\section{Otrzymane wyniki}

\section{Bibliografia}

\printbibliography

\end{document}
